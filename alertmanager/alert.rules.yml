groups:
  - name: host_alerts
    rules:
      - alert: HostHighCpuLoad
        # This expression calculates the percentage of non-idle CPU time over 5 minutes.
        # It's a more accurate measure of load than node_load1.
        expr: 100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 85
        for: 10m
        labels:
          severity: 'warning'
        annotations:
          summary: "Host high CPU load on {{ $labels.instance }}"
          description: "CPU usage has been above 85% for 10 minutes. Current value: {{ $value | printf \"%.2f\" }}%."

      - alert: HostOutOfMemory
        expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 < 10
        for: 5m
        labels:
          severity: 'critical'
        annotations:
          summary: "Host out of memory on {{ $labels.instance }}"
          description: "Available memory is less than 10%. Current value: {{ $value | printf \"%.2f\" }}%."

      - alert: HostHighDiskUsage
        # This expression ignores temporary filesystems to prevent false positives.
        expr: (node_filesystem_avail_bytes{mountpoint="/",fstype!~"tmpfs|squashfs"} / node_filesystem_size_bytes{mountpoint="/",fstype!~"tmpfs|squashfs"}) * 100 < 15
        for: 15m
        labels:
          severity: 'critical'
        annotations:
          summary: "Host high disk usage on {{ $labels.instance }}"
          description: "Root disk space is less than 15%. Current value: {{ $value | printf \"%.2f\" }}%."

      - alert: HostSystemDown
        # This alert fires if a node-exporter target has been unreachable for 5 minutes.
        expr: up{job="node-exporter"} == 0
        for: 5m
        labels:
          severity: 'critical'
        annotations:
          summary: "Host system down: {{ $labels.instance }}"
          description: "The node-exporter on {{ $labels.instance }} has been unreachable for more than 5 minutes."

  - name: container_alerts
    rules:
      - alert: ContainerCpuUsageHigh
        # This expression now groups by hostname AND name to preserve the host label.
        expr: sum by (hostname, name) (rate(container_cpu_usage_seconds_total{name!="", name!~"prometheus|grafana|cadvisor|alertmanager|node-exporter|portainer|dcgm-exporter"}[5m])) > 2
        for: 10m
        labels:
          severity: 'warning'
        annotations:
          summary: "High CPU on container {{ $labels.name }} on host {{ $labels.hostname }}"
          description: "Container '{{ $labels.name }}' on host '{{ $labels.hostname }}' has been using more than 2 CPU cores for 10 minutes."

      - alert: ContainerMemoryHigh
        # This expression now groups by hostname AND name to preserve the host label.
        expr: sum by (hostname, name) (container_memory_usage_bytes{name!="", name!~"prometheus|grafana|cadvisor|alertmanager|node-exporter|portainer|dcgm-exporter"}) > 4e9
        for: 10m
        labels:
          severity: 'warning'
        annotations:
          summary: "High memory on container {{ $labels.name }} on host {{ $labels.hostname }}"
          description: "Container '{{ $labels.name }}' on host '{{ $labels.hostname }}' is using more than 4GB of RAM. Current usage: {{ $value | humanize1024 }}B."

      # - alert: ContainerRestarting
      #   # This alert is more precise, firing if a container restarts more than twice in 15 minutes.
      #   expr: rate(container_restarts_total{name!=""}[15m]) * 60 * 15 > 2
      #   for: 1m
      #   labels:
      #     severity: 'critical'
      #   annotations:
      #     summary: "Container {{ $labels.name }} is in a crash loop"
      #     description: "Container '{{ $labels.name }}' has restarted more than twice in the last 15 minutes."

      # - alert: ContainerCrashLooping
      #   # This alert detects a container that is stuck in a restart loop by counting scrape failures.
      #   # It fires if scrapes for a container have failed more than 3 times in the last 15 minutes.
      #   expr: count_over_time(up{job="cadvisor", name!="", name!~"prometheus|grafana|cadvisor|alertmanager|node-exporter|portainer|dcgm-exporter"}[15m] == 0) > 3
      #   for: 1m
      #   labels:
      #     severity: 'critical'
      #   annotations:
      #     summary: "Container {{ $labels.name }} on host {{ $labels.hostname }} is crash-looping"
      #     description: "Container '{{ $labels.name }}' on host '{{ $labels.hostname }}' is unstable and failing to respond to monitoring scrapes. It has failed more than 3 scrapes in the last 15 minutes."

      - alert: ContainerKilled
        # This is a long-term fallback if a container disappears for 15 minutes.
        expr: time() - container_last_seen{name!="", name!~"prometheus|grafana|cadvisor|alertmanager|node-exporter|portainer|dcgm-exporter"} > 900
        for: 0m
        labels:
          severity: 'critical'
        annotations:
          summary: "App container {{ $labels.name }} on host {{ $labels.hostname }} has disappeared"
          description: "The application container '{{ $labels.name }}' on host '{{ $labels.hostname }}' has been missing for over 15 minutes. It may have crashed or been removed."
